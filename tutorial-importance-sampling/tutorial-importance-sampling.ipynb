{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 1: Probabilistic Modeling and Importance Sampling\n",
    "\n",
    "This tutorial shows how to write a probabilistic model in Gen, and how to implement a simple inference algorithm for this model.\n",
    "\n",
    "Specifically, will implement an inference algorithm that infers the probable destination of an autonomous agent from its observed motion in a two-dimensional environment with obstacles. The algorithm will employ a generative model that includes (i) a prior distribution on the destination of the agent, and (ii) an algorithmic model for how the agent plans its movement based on its destination, (iii) a statistical model of the noise in our measurements of the agent's motion. This class of model draws inspiration from models of human cognition from the computational cognitive science literature [1]. We use this model because the results of inference are intuitive from everyday life and are straightforward to visualize.\n",
    "\n",
    "We will use importance sampling for inference. We will start with a basic importance sampling algorithm that uses a default proposal distribution, and then we will develop custom proposal distributions that give more efficient importance sampling algorithms.\n",
    "\n",
    "We will break down this modeling and inference tasks into the following steps:\n",
    "\n",
    "- **Step 1:** Implement geometric primitives for a two-dimensional scene that contains obstacles.\n",
    "\n",
    "- **Step 2:** Implement a planning algorithm that takes the two-dimensional scene, and a starting point within the scene, and a destination point within the scene, and generates an efficient (short) path from the starting point to the destination point.\n",
    "\n",
    "- **Step 3:** Write a generative function for the observed motion of of an autonomous agent, using the Julia code written in Steps 1 and 2.\n",
    "\n",
    "- **Step 4:** Explore the the assumptions, or prior beliefs, that our inferences will be based on, by sampling many traces of the generative function and visualizing them.\n",
    "\n",
    "- **Step 5:** Use a simple importance sampling algorithm to sample probable destination points for the agent, given an example data set of observed motion.\n",
    "\n",
    "- **Step 6:** Writing a custom proposal distribution for use with importance sampling.\n",
    "\n",
    "- **Step 7:** Learning a custom proposal distribution for use with importance sampling.\n",
    "\n",
    "[1] Baker, Chris L., Rebecca Saxe, and Joshua B. Tenenbaum. \"Action understanding as inverse planning.\" Cognition 113.3 (2009): 329-349."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "\n",
    "First, we load the `Gen` Julia package, which brings into scope the built-in Gen modeling languages and inference library methods. We won't use Gen itself until Step 3, but we load it here because packages are usually loaded at the beginning of a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also load the `GenViz` Julia package, which is a JavaScript-based visualization framework designed for use with Gen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using GenViz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start a visualization server that we will use throughout the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "server = VizServer(8000)\n",
    "sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also make use of the [`PyPlot`](https://github.com/JuliaPy/PyPlot.jl) Julia package, which wraps [matplotlib](https://matplotlib.org/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using PyPlot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the `median` method from the `Statistics` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Statistics: median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will need the `JLD` Julia package to load some precomputed data from disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using JLD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Implement geometry of a two-dimensional scene with obstacles.\n",
    "\n",
    "This step is implemented using regular Julia code. We have provided some of the basic geometric primitives in the following file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "include(\"geometric_primitives.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file defines two-dimensional `Point` data type with fields `x` and `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = Point(1.0, 2.0)\n",
    "println(point.x)\n",
    "println(point.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file defines a method that computes the distance between two points: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist(Point(1.0, 1.0), Point(0.0, 0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file also defines an `Obstacle` data type, which represents a polygonal obstacle in a two-dimensional scene, that is constructed from a list of vertices. Here, we construct a square:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obstacle = Obstacle([Point(0.0, 0.0), Point(1.0, 0.0), Point(0.0, 1.0), Point(1.0, 1.0)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file also defines a method to test whether an obstacle intersects with a line segment, which is defined by a start point and an end point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(obstacle_intersects_line_segment(obstacle, Point(-1.0, 0.5), Point(2.0, 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "println(obstacle_intersects_line_segment(obstacle, Point(-1.0, 1.5), Point(2.0, 1.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these geometric primitives, we define a data type to represent the two-dimensional scene. The scene spans a rectangle of on the two-dimensional x-y plane, and contains a list of obstacles. Each obstacle is a polygon defined by a list of vertex points. We also define a method to compute whether a given line is obstructed by any obstacles in the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Scene\n",
    "    xmin::Float64\n",
    "    xmax::Float64\n",
    "    ymin::Float64\n",
    "    ymax::Float64\n",
    "    obstacles::Vector{Obstacle}\n",
    "end\n",
    "\n",
    "Scene(xmin, xmax, ymin, ymax) = Scene(xmin, xmax, ymin, ymax, Obstacle[])\n",
    "\n",
    "add_obstacle!(scene, obstacle::Obstacle) = push!(scene.obstacles, obstacle)\n",
    "\n",
    "function line_is_obstructed(scene::Scene, a1::Point, a2::Point)\n",
    "    for obstacle in scene.obstacles\n",
    "        if obstacle_intersects_line_segment(obstacle, a1, a2)\n",
    "            return true\n",
    "        end\n",
    "    end\n",
    "    false\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we write some methods that allow us to concisely construct walls (line-shaped obstacles that are either vertically or horizontally oriented), and square-shaped obstacles (representing trees)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_wall(vertical::Bool, start::Point, length::Float64, thickness::Float64)\n",
    "    vertices = Vector{Point}(undef, 4)\n",
    "    vertices[1] = start\n",
    "    dx = vertical ? thickness : length\n",
    "    dy = vertical ? length : thickness\n",
    "    vertices[2] = Point(start.x + dx, start.y)\n",
    "    vertices[3] = Point(start.x + dx, start.y + dy) \n",
    "    vertices[4] = Point(start.x, start.y + dy)\n",
    "    Obstacle(vertices)\n",
    "end \n",
    "\n",
    "function make_tree(center::Point, size::Float64)\n",
    "    vertices = Vector{Point}(undef, 4)\n",
    "    vertices[1] = Point(center.x - size/2, center.y - size/2)\n",
    "    vertices[2] = Point(center.x + size/2, center.y - size/2)\n",
    "    vertices[3] = Point(center.x + size/2, center.y + size/2)\n",
    "    vertices[4] = Point(center.x - size/2, center.y + size/2)\n",
    "    Obstacle(vertices)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now construct a scene value that we will use in the rest of the tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scene = Scene(0, 1, 0, 1)\n",
    "add_obstacle!(scene, make_tree(Point(0.30, 0.20), 0.1))\n",
    "add_obstacle!(scene, make_tree(Point(0.83, 0.80), 0.1))\n",
    "add_obstacle!(scene, make_tree(Point(0.80, 0.40), 0.1))\n",
    "horizontal = false\n",
    "vertical = true\n",
    "wall_thickness = 0.02\n",
    "add_obstacle!(scene, make_wall(horizontal, Point(0.20, 0.40), 0.40, wall_thickness))\n",
    "add_obstacle!(scene, make_wall(vertical, Point(0.60, 0.40), 0.40, wall_thickness))\n",
    "add_obstacle!(scene, make_wall(horizontal, Point(0.60 - 0.15, 0.80), 0.15 + wall_thickness, wall_thickness))\n",
    "add_obstacle!(scene, make_wall(horizontal, Point(0.20, 0.80), 0.15, wall_thickness))\n",
    "add_obstacle!(scene, make_wall(vertical, Point(0.20, 0.40), 0.40, wall_thickness));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the scene below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "info = Dict(\"scene\" => scene)\n",
    "viz = Viz(server, joinpath(@__DIR__, \"overlay-viz/dist\"), info)\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Implement a simple planning algorithm\n",
    "\n",
    "In this step, we implement a simple planning algorithm based on the rapidly exploring random tree (RRT) algorithm [2]. The planning algorithm will take as input (i) the scene, (ii) the start point, and (iii) the destination point, and will produce a sequence of points that starts with the start point and ends with the destination point, such the line of sight between each consecutive point does not intersect any obstacles, or return failure if no path could be found.\n",
    "\n",
    "[2] Rapidly-exploring random trees: A new tool for path planning. S. M. LaValle. TR 98-11, Computer Science Dept., Iowa State University, October 1998,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load an implementation of the RRT algorithm from the following file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "include(\"rrt.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file defines a method `generate_rrt` that takes a scene, a starting point, and algorithm parameters, and returns an `RRT` value, which represents a tree rooted at the starting point that fills the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = Point(0.1, 0.1)\n",
    "tree = generate_rrt(scene, start, 300, 3.0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the resulting tree on top of the scene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "info = Dict(\"start\"=> start, \"scene\" => scene, \"tree_edges\" => get_edges(tree))\n",
    "viz = Viz(server, joinpath(@__DIR__, \"overlay-viz/dist\"), info)\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a RRT, and a destination point, we can find a path from the root of the RRT to the destination point, by finding a node on the tree that has a clear line-of-sight to the destination node, and is also as close as possible to the destination node. We then walk back from this node along the edges of the tree to the route to construct the path. If there is no node on the tree with a clear line-of-sight to the destination, we return the value `nothing`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Path\n",
    "    points::Vector{Point}\n",
    "end\n",
    "\n",
    "function get_path_to_dest(tree::RRT, destination::Point)\n",
    "    \n",
    "    # find a node in the tree with a clear line-of-sight to the destination\n",
    "    best_node = tree.nodes[1]\n",
    "    min_cost = Inf\n",
    "    path_found = false\n",
    "    for node in tree.nodes\n",
    "        clear_path = !line_is_obstructed(scene, node.conf, destination)\n",
    "        cost = node.dist_from_start + (clear_path ? dist(node.conf, destination) : Inf)\n",
    "        if cost < min_cost\n",
    "            path_found = true\n",
    "            best_node = node\n",
    "            min_cost = cost\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    if path_found\n",
    "        \n",
    "        # walk from the best node to the root of the tree to construct the path\n",
    "        points = Point[destination]\n",
    "        node = best_node\n",
    "        while node.parent != nothing\n",
    "            push!(points, node.conf)\n",
    "            node = node.parent\n",
    "        end\n",
    "        push!(points, root(tree).conf)\n",
    "        Path(reverse(points))\n",
    "    else\n",
    "        \n",
    "        # return nothing if no path was found\n",
    "        nothing\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize an example path below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_edges(path::Path)\n",
    "    edges = Tuple{Point,Point}[]\n",
    "    for i=1:length(path.points)-1\n",
    "        push!(edges, (path.points[i], path.points[i+1]))\n",
    "    end\n",
    "    edges\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest = Point(0.5, 0.5)\n",
    "path = get_path_to_dest(tree, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "info = Dict(\"start\"=> start, \"dest\" => dest, \"scene\" => scene,\n",
    "    \"tree_edges\" => get_edges(tree), \"path_edges\" => get_edges(path))\n",
    "viz = Viz(server, joinpath(@__DIR__, \"overlay-viz/dist\"), info)\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paths along the tree that are generated by the RRT algorithm are generally not very direct. We want our agent to take fairly direct paths from its starting location to the destination. Therefore, we use the following path-refinement procedure to optimize the path points to shorten the length of the path while still avoiding obstruction by obstacles. You don't need to worry about the details of this procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function refine_path(scene::Scene, original::Path, iters::Int, std::Float64)\n",
    "    new_points = copy(original.points)\n",
    "    num_interior_points = length(original.points) -2\n",
    "    if num_interior_points == 0\n",
    "        return original\n",
    "    end\n",
    "    for i=1:iters\n",
    "        \n",
    "        # propose an adjustment to one of the interior points on the path (not the first or last point)\n",
    "        point_idx = 2 + (i % num_interior_points)\n",
    "        prev_point = new_points[point_idx-1]\n",
    "        point = new_points[point_idx]\n",
    "        next_point = new_points[point_idx+1]\n",
    "        adjusted_point = Point(point.x + randn() * std, point.y + randn() * std)\n",
    "        \n",
    "        # check if the new path is obstructed by obstacles\n",
    "        ok_backward = !line_is_obstructed(scene, prev_point, adjusted_point)\n",
    "        ok_forward = !line_is_obstructed(scene, adjusted_point, next_point)\n",
    "        \n",
    "        # accept the adjustment if it is not obstructed by obstacles and it reduces the length of the path\n",
    "        if ok_backward && ok_forward\n",
    "            new_dist = dist(prev_point, adjusted_point) + dist(adjusted_point, next_point)\n",
    "            cur_dist = dist(prev_point, point) + dist(point, next_point)\n",
    "            if new_dist < cur_dist\n",
    "                new_points[point_idx] = adjusted_point\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    Path(new_points)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = refine_path(scene, path, 2000, 1.)\n",
    "info = Dict(\"start\"=> start, \"dest\" => dest, \"scene\" => scene,\n",
    "    \"tree_edges\" => get_edges(tree), \"path_edges\" => get_edges(path))\n",
    "viz = Viz(server, joinpath(@__DIR__, \"overlay-viz/dist\"), info)\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we combine each of the steps we just defined into a path-planning function. If a path could not be found, we return the value `nothing`. Otherwise, we return a `Path` value The path-planning function has parameters for how to grow the RRT (`rrt_iters` and `rrt_dt`) and how to perform the refinement (`refine_iters` and `refine_std`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct PlannerParams\n",
    "    rrt_iters::Int\n",
    "    rrt_dt::Float64\n",
    "    refine_iters::Int\n",
    "    refine_std::Float64\n",
    "end\n",
    "\n",
    "function plan_path(start::Point, dest::Point, scene::Scene, params::PlannerParams)\n",
    "    \n",
    "    # Generate a rapidly exploring random tree\n",
    "    tree = generate_rrt(scene, start, params.rrt_iters, params.rrt_dt)\n",
    "\n",
    "    # Find a route from the root of the tree to a node on the tree that has a line-of-sight to the destination\n",
    "    maybe_path = get_path_to_dest(tree, dest)\n",
    "    \n",
    "    if maybe_path == nothing\n",
    "        \n",
    "        # No route found\n",
    "        return (nothing, tree)\n",
    "    else\n",
    "        \n",
    "        # Route found\n",
    "        path = something(maybe_path)\n",
    "        refined_path = refine_path(scene, maybe_path, params.refine_iters, params.refine_std)\n",
    "        return (refined_path, tree)\n",
    "    end\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run the end-to-end path planning procedure. Run the cell below a few times to get a sense for the variability in the path planner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(path, tree) = plan_path(start, dest, scene, PlannerParams(300, 3.0, 2000, 1.))\n",
    "info = Dict(\"start\"=> start, \"dest\" => dest, \"scene\" => scene,\n",
    "    \"tree_edges\" => get_edges(tree), \"path_edges\" => get_edges(path))\n",
    "viz = Viz(server, joinpath(@__DIR__, \"overlay-viz/dist\"), info)\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need a model for how the agent moves along its path.\n",
    "We will assume that the agent moves along its path a constant speed. The cell below defines a method that computes the locations of the agent at a set of timepoints, given the path and the speed of the agent. You don't need to worry about the details of this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_distances_from_start(path::Path)\n",
    "    distances_from_start = Vector{Float64}(undef, length(path.points))\n",
    "    distances_from_start[1] = 0.0\n",
    "    for i=2:length(path.points)\n",
    "        distances_from_start[i] = distances_from_start[i-1] + dist(path.points[i-1], path.points[i])\n",
    "    end\n",
    "    return distances_from_start\n",
    "end\n",
    "\n",
    "function walk_path(path::Path, speed::Float64, dt::Float64, num_ticks::Int)\n",
    "    distances_from_start = compute_distances_from_start(path)\n",
    "    locations = Vector{Point}(undef, num_ticks)\n",
    "    locations[1] = path.points[1]\n",
    "    t = 0.\n",
    "    for time_idx=1:num_ticks\n",
    "        desired_distance = t * speed\n",
    "        used_up_time = false\n",
    "        # NOTE: can be improved (iterate through path points along with times)\n",
    "        for i=2:length(path.points)\n",
    "            prev = path.points[i-1]\n",
    "            cur = path.points[i]\n",
    "            dist_to_prev = dist(prev, cur)\n",
    "            if distances_from_start[i] >= desired_distance\n",
    "                # we overshot, the location is between i-1 and i\n",
    "                overshoot = distances_from_start[i] - desired_distance\n",
    "                @assert overshoot <= dist_to_prev\n",
    "                past_prev = dist_to_prev - overshoot\n",
    "                frac = past_prev / dist_to_prev\n",
    "                locations[time_idx] = Point(prev.x * (1. - frac) + cur.x * frac,\n",
    "                                     prev.y * (1. - frac) + cur.y * frac)\n",
    "                used_up_time = true\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "        if !used_up_time\n",
    "            # sit at the goal indefinitely\n",
    "            locations[time_idx] = path.points[end]\n",
    "        end\n",
    "        t += dt\n",
    "    end\n",
    "    locations\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Write a generative function for the motion of an autonomous agent\n",
    "\n",
    "We now can write a generative function that models the behavior of an autonomous agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function model(scene::Scene, dt::Float64, num_ticks::Int)\n",
    "\n",
    "    # sample the start point of the agent from the prior\n",
    "    start_x = @addr(uniform(0, 1), :start_x)\n",
    "    start_y = @addr(uniform(0, 1), :start_y)\n",
    "    start = Point(start_x, start_y)\n",
    "\n",
    "    # sample the destination point of the agent from the prior\n",
    "    dest_x = @addr(uniform(0, 1), :dest_x)\n",
    "    dest_y = @addr(uniform(0, 1), :dest_y)\n",
    "    dest = Point(dest_x, dest_y)\n",
    "\n",
    "    # plan a path that avoids obstacles in the scene\n",
    "    (maybe_path, _) = plan_path(start, dest, scene, PlannerParams(300, 3.0, 2000, 1.))\n",
    "    \n",
    "    # sample the speed from the prior\n",
    "    speed = @addr(uniform(0, 1), :speed)\n",
    "\n",
    "    if maybe_path == nothing\n",
    "        \n",
    "        # path planning failed, assume the agent stays as the start location indefinitely\n",
    "        locations = fill(start, num_ticks)\n",
    "    else\n",
    "        \n",
    "        # path planning succeeded, move along the path at constant speed\n",
    "        path = something(maybe_path)\n",
    "        locations = walk_path(path, speed, dt, num_ticks)\n",
    "    end\n",
    "\n",
    "    # generate noisy measurements\n",
    "    noise = 0.01\n",
    "    measurements = Vector{Point}(undef, num_ticks)\n",
    "    for (i, point) in enumerate(locations)\n",
    "        x = @addr(normal(point.x, noise), :meas => i => :x)\n",
    "        y = @addr(normal(point.y, noise), :meas => i => :y)\n",
    "        measurements[i] = Point(x, y)\n",
    "    end\n",
    "\n",
    "    (start, dest, speed, noise, maybe_path, locations, measurements)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a time step of `dt = 0.1` and we will assume that 10 measurements are taken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "const dt = 0.1\n",
    "const num_ticks = 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now perform traced executions the generative function using Gen's `initialize` method. Here, we obtain a traced execution, then obtain the assignment to random choices made during the execution, and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trace, _) = initialize(model, (scene, dt, num_ticks));\n",
    "assmt = get_assmt(trace)\n",
    "println(assmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Explore the assumptions of our model\n",
    "\n",
    "Here we explore the assumptions of the model by sampling many traces from the generative function and visualizing them. We have created a visualization specialized for this generative function for use with the `GenViz` package, in the directory `grid-viz/dist`. We have also defined a `trace_to_dict` method to convert the trace into a value that can be easily serialized into a JSON string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function trace_to_dict(trace)\n",
    "    args = get_args(trace)\n",
    "    (scene, dt, num_ticks) = args\n",
    "\n",
    "    retval = get_retval(trace)\n",
    "    (start, dest, speed, noise, maybe_path, locations, measurements) = retval\n",
    "\n",
    "    d = Dict()\n",
    "\n",
    "    # scene (the obstacles)\n",
    "    d[\"scene\"] = scene\n",
    "\n",
    "    # the path\n",
    "    if maybe_path != nothing\n",
    "        d[\"path\"] = maybe_path.points\n",
    "    else\n",
    "        d[\"path\"] = []\n",
    "    end\n",
    "\n",
    "    # start and destination location\n",
    "    d[\"start\"] = start\n",
    "    d[\"dest\"] = dest\n",
    "\n",
    "    # observed points\n",
    "    d[\"measurements\"] = measurements\n",
    "\n",
    "    d\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Random\n",
    "Random.seed!(3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "viz = Viz(server, joinpath(@__DIR__, \"grid-viz/dist\"), [])\n",
    "constraints = DynamicAssignment()\n",
    "constraints[:start_x] = 0.1\n",
    "constraints[:start_y] = 0.1\n",
    "for i=1:12\n",
    "    (trace, _) = initialize(model, (scene, dt, num_ticks), constraints)\n",
    "    putTrace!(viz, i, trace_to_dict(trace))\n",
    "end\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this visualziation, the start location is represented by a blue dot, and the destination is represented by a red dot. The measured coordinates at each time point are represented by black dots. The path, if path planning was succesfull, is shown as a gray line fro the start point to the destination point. Notice that the speed of the agent is different in each case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Use a simple importance sampling algorithm\n",
    "\n",
    "We now write a simple algorithm for inferring the destination of an agent given (i) the scene, (ii) the start location of the agent, and (iii) a sequence of measured locations of the agent for each tick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start = Point(0.1, 0.1)\n",
    "\n",
    "measurements = [\n",
    "    Point(0.0980245, 0.104775),\n",
    "    Point(0.113734, 0.150773),\n",
    "    Point(0.100412, 0.195499),\n",
    "    Point(0.114794, 0.237386),\n",
    "    Point(0.0957668, 0.277711),\n",
    "    Point(0.140181, 0.31304),\n",
    "    Point(0.124384, 0.356242),\n",
    "    Point(0.122272, 0.414463),\n",
    "    Point(0.124597, 0.462056),\n",
    "    Point(0.126227, 0.498338)];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(path, tree) = plan_path(start, dest, scene, PlannerParams(300, 3.0, 2000, 1.))\n",
    "info = Dict(\"start\" => start, \"scene\" => scene, \"measurements\" => measurements)\n",
    "viz = Viz(server, joinpath(@__DIR__, \"overlay-viz/dist\"), info)\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we write a simple inference program based on the `importance_resampling` method from Gen's inference library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function do_inference(scene::Scene, dt::Float64, num_ticks::Int, start::Point,\n",
    "                      measurements::Vector{Point}, num_particles::Int)\n",
    "    \n",
    "    # construct observations assignment\n",
    "    observations = DynamicAssignment()\n",
    "    observations[:start_x] = start.x\n",
    "    observations[:start_y] = start.y\n",
    "    for (i, m) in enumerate(measurements)\n",
    "        observations[:meas => i => :x] = m.x\n",
    "        observations[:meas => i => :y] = m.y\n",
    "    end\n",
    "    \n",
    "    # use importance sampling with resampling to obtain an inferred trace\n",
    "    (trace, _) = importance_resampling(model, (scene, dt, num_ticks), observations, num_particles)\n",
    "    \n",
    "    trace\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we run this algorithm 1000 times, using 50 particles for each run, and visualize the inferred destinations. The inferred destinations should appear as red dots on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "info = Dict(\"measurements\" => measurements, \"scene\" => scene, \"start\" => start)\n",
    "viz = Viz(server, joinpath(@__DIR__, \"overlay-viz/dist\"), info)\n",
    "openInNotebook(viz)\n",
    "sleep(5)\n",
    "for i=1:1000\n",
    "    trace = do_inference(scene, dt, num_ticks, start, measurements, 50)\n",
    "    putTrace!(viz, i, trace_to_dict(trace))\n",
    "end\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Write a custom proposal to improve importance sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic importance sampling algorithm shown above uses a *default proposal distribution* for the latent variables. Below we compare the distribution of the speed sampled by the default proposal with the distribution on speed obtained from the inference algorithm when run on the data set above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we generate some traces from the default proposal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prior_traces = []\n",
    "for i=1:250\n",
    "    (trace, _) = initialize(model, (scene, dt, num_ticks), EmptyAssignment())\n",
    "    push!(prior_traces, trace)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also generate some traces from the inference algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "posterior_traces = []\n",
    "for i=1:250\n",
    "    trace = do_inference(scene, dt, num_ticks, start, measurements, 50)\n",
    "    push!(posterior_traces, trace)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then extract the value of the `:speed` random choice from each trace, and compare the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(12, 4))\n",
    "\n",
    "subplot(2, 1, 1)\n",
    "speeds = [let assmt = get_assmt(t); assmt[:speed] end for t in prior_traces];\n",
    "scatter(speeds, randn(length(prior_traces)))\n",
    "gca()[:set_xlim](0, 1)\n",
    "title(\"Speed samples from the default proposal distribution\")\n",
    "\n",
    "subplot(2, 1, 2)\n",
    "speeds = [let assmt = get_assmt(t); assmt[:speed] end for t in posterior_traces];\n",
    "scatter(speeds, randn(length(posterior_traces)))\n",
    "gca()[:set_xlim](0, 1)\n",
    "title(\"Speed samples from the approximate posterior\")\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the posterior distribution on the speed is fairly concentrated in the range 0.4-0.5. We could make our importance sampling algorithm more efficient if we could use a proposal that is closer to this approximate posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the measurements, it seems intuitive that we should be able to come up with a good heuristic estimate of the speed, using the distance between consecutive measurements. We ignore successive measurements that are too close together, because these could be sampled from the part of the trajectory after the agent has already reached its destination and stopped. Below we write a function that computes a guess for the speed by taking the median of distance between consecutive data points. This heuristic is based on the assumption that the majority of the agent's paths will be composed of straight-line segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function guess_speed(measurements::Vector{Point}, dt::Float64)\n",
    "    n = length(measurements)\n",
    "    dists = Vector{Float64}()\n",
    "    num_used = 0\n",
    "    for i=1:n-1\n",
    "        d = dist(measurements[i], measurements[i+1])\n",
    "        if d > 0.03\n",
    "            push!(dists, d)\n",
    "            num_used += 1\n",
    "        end\n",
    "    end\n",
    "    if num_used == 0\n",
    "        guess = NaN\n",
    "    else\n",
    "        guess = median(dists) / dt\n",
    "    end\n",
    "    (guess, num_used)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this heuristic estimate is unlikely to be accurate if the path planner failed or if the true speed is small, because in these cases the estimate will be completely or partially dominated by the contributions from the measurement noise. Therefore, if there are not enough sufficiently large consecutive distance measurements, we revert to the original default proposal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function propose_speed(guess::Float64, num_used::Int)\n",
    "    if num_used > 3\n",
    "        N = 40\n",
    "        alpha = guess * (N - 2) + 1\n",
    "        beta = N - alpha\n",
    "        @addr(beta_uniform(0.7, alpha, beta), :speed)\n",
    "    else\n",
    "        @addr(uniform_continuous(0, 1), :speed)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we sample from the custom propsal, and find that it is indeed more concentrated around the posterior distibution for this particular data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(12, 2))\n",
    "\n",
    "speeds = [propose_speed(guess_speed(measurements, dt)...) for _=1:length(posterior_traces)];\n",
    "scatter(speeds, randn(length(posterior_traces)))\n",
    "gca()[:set_xlim](0, 1)\n",
    "title(\"Speed samples from the custom proposal\")\n",
    "\n",
    "tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also understand the behavior of the custom proposal on various types of data sets. Below, we take a set of traces sample from the generative model, and plot the true speed (dashed blue line), heuristic estimate (red line), and the resulting custom proposal distribution (orange line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import Statistics\n",
    "PyPlot.figure(figsize=(10, 4))\n",
    "for (i, trace) in enumerate(prior_traces[1:10])\n",
    "    PyPlot.subplot(2, 5, i)\n",
    "    (start, dest, speed, noise, maybe_path, locations, measurements) = get_retval(trace)\n",
    "    (guess, num_used) = guess_speed(measurements, dt)\n",
    "    PyPlot.plot([0.1, 0.1], [0, 1], \"k\")\n",
    "    PyPlot.plot([1, 1], [0, 1], \"k\")\n",
    "    PyPlot.plot([guess, guess], [0, 1], \"r\")\n",
    "    PyPlot.plot([speed, speed], [0, 1], \"--\")\n",
    "    pdfs = [let\n",
    "                assmt = DynamicAssignment();\n",
    "                assmt[:speed] = s;\n",
    "                exp(assess(propose_speed, (guess, num_used), assmt)[1])\n",
    "            end\n",
    "        for s in 0.0:0.01:1.0]\n",
    "    PyPlot.plot(0.0:0.01:1.0, pdfs / maximum(pdfs))\n",
    "    ax = PyPlot.gca()\n",
    "    ax[:set_xlim](0, 1.5)\n",
    "    ax[:set_ylim](0, 1.05)\n",
    "end\n",
    "PyPlot.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding data sets are shown below. We find that the proposal is accurate in many cases with sufficiently large speeds and correctly reverts to a generic proposal when the heuristic estimate is unlikely to be accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "viz = Viz(server, joinpath(@__DIR__, \"grid-viz/dist\"), [])\n",
    "for (i, trace) in enumerate(prior_traces[1:10])\n",
    "    putTrace!(viz, i, trace_to_dict(trace))\n",
    "end\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use this custom proposal in a new inference algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function do_inference_custom(scene::Scene, dt::Float64, num_ticks::Int,\n",
    "                             start::Point, measurements::Vector{Point},\n",
    "                             num_particles::Int)\n",
    "    (guess, num_used) = guess_speed(measurements, dt)\n",
    "    \n",
    "    observations = DynamicAssignment()\n",
    "    observations[:start_x] = start.x\n",
    "    observations[:start_y] = start.y\n",
    "    for (i, m) in enumerate(measurements)\n",
    "        observations[:meas => i => :x] = m.x\n",
    "        observations[:meas => i => :y] = m.y\n",
    "    end\n",
    "    \n",
    "    # use importance sampling with resampling to obtain an inferred trace\n",
    "    (trace, _) = importance_resampling(model, (scene, dt, num_ticks), observations, \n",
    "        propose_speed, (guess, num_used), num_particles)\n",
    "    \n",
    "    trace\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show results of importance sampling inference (50 particles)\n",
    "viz = Viz(server, joinpath(@__DIR__, \"overlay-viz/dist\"), info)\n",
    "openInNotebook(viz)\n",
    "sleep(5)\n",
    "for i=1:1000\n",
    "    trace = do_inference_custom(scene, dt, num_ticks, start, measurements, 50)\n",
    "    putTrace!(viz, i, trace_to_dict(trace))\n",
    "end\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quantify the change in performance of the algorithm when using the default and custom proposals by comparing the output inferred destination distributions against a gold-standard destination distribution obtained using a large amount of computation. The cell below runs the inference algorithm with the default proposal 1000 times, where each run uses a large number of particles (10000). This cell takes two hours to run. We have already precomputed the results, and we have made this cell not runnable."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "start_time = time_ns()\n",
    "gold_standard_traces = []\n",
    "for i=1:1000\n",
    "    if i % 10 == 0\n",
    "        elapsed = (time_ns() - start_time)/1e9\n",
    "        println(\"$i of 1000, elapsed: $elapsed\")\n",
    "    end\n",
    "    push!(gold_standard_traces, do_inference(scene, dt, num_ticks, start, measurements, 10000))\n",
    "end\n",
    "println((time_ns() - start_time)/1e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we write a function that forms a histogram-based density estimate of the distribution on the destination from a collection of traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_location_histogram(traces, nrows::Int, ncols::Int, scene::Scene)\n",
    "    locations = [let a = get_assmt(t); Point(a[:dest_x], a[:dest_y]) end for t in traces]\n",
    "    counts = fill(0.01, nrows * ncols)\n",
    "    xspan = scene.xmax - scene.xmin\n",
    "    yspan = scene.ymax - scene.ymin\n",
    "    for loc in locations\n",
    "        row = Int(floor((loc.y - scene.ymin) / yspan * nrows))\n",
    "        col = Int(floor((loc.x - scene.xmin) / xspan * ncols))\n",
    "        @assert row < nrows\n",
    "        @assert col < ncols\n",
    "        counts[row * ncols + col + 1] += 1\n",
    "    end\n",
    "    freqs = counts ./ sum(counts)\n",
    "    freqs\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 10 rows and 10 columns in the histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nrows = 10\n",
    "ncols = 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now generate the gold-standard histogram from the gold-standard traces. We have precomputed the result, so we have made this cell not runnable."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "gold_standard_histogram = make_location_histogram(gold_standard_traces, nrows, ncols, scene);\n",
    "save(\"gold_standard_histogram.jld\", gold_standard_histogram, \"gold_standard_histogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the precomputed results from disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gold_standard_histogram = load(\"gold_standard_histogram.jld\", \"gold_standard_histogram\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we generate histograms for each of the algorithms we want to compare to the gold standard. We test the default proposal and custom proposal algorithms, for various numbers of particles. We also measure the running time per output sample. This cell takes a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_histograms = Dict{Int,Vector{Float64}}()\n",
    "default_times = Dict{Int,Vector{Float64}}()\n",
    "custom_histograms = Dict{Int,Vector{Float64}}()\n",
    "custom_times = Dict{Int,Vector{Float64}}()\n",
    "num_particles_list = [1, 3, 10, 30, 100]\n",
    "\n",
    "nruns = 1000\n",
    "for n in num_particles_list\n",
    "    \n",
    "    println(\"evaluating algorithms with num_particles=$n\")\n",
    "    \n",
    "    # run importance sampling with default proposal\n",
    "    traces = Vector{Any}(undef, nruns)\n",
    "    times = Vector{Float64}(undef, nruns)\n",
    "    for i=1:nruns\n",
    "        start_time = time_ns()\n",
    "        traces[i] = do_inference(scene, dt, num_ticks, start, measurements, n)\n",
    "        times[i] = (time_ns() - start_time)/1e9\n",
    "    end\n",
    "    default_histograms[n] = make_location_histogram(traces, nrows, ncols, scene)\n",
    "    default_times[n] = times\n",
    "    \n",
    "    # run importance sampling with custom proposal\n",
    "    traces = Vector{Any}(undef, nruns)\n",
    "    times = Vector{Float64}(undef, nruns)\n",
    "    for i=1:nruns\n",
    "        start_time = time_ns()\n",
    "        traces[i] = do_inference_custom(scene, dt, num_ticks, start, measurements, n)\n",
    "        times[i] = (time_ns() - start_time)/1e9\n",
    "    end\n",
    "    custom_histograms[n] = make_location_histogram(traces, nrows, ncols, scene)\n",
    "    custom_times[n] = times\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we write a function to compute the KL divergence between two discrete distributions. We will use the KL divergence to measure the difference between the gold-standard output distribution and the output distributions of the algorithms we are evaluating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function kl_divergence(dist1::Vector{Float64}, dist2::Vector{Float64})\n",
    "    sum(dist1 .* (log.(dist1) .- log.(dist2)))\n",
    "end\n",
    "\n",
    "default_kls = [kl_divergence(gold_standard_histogram, default_histograms[n]) for n in num_particles_list]\n",
    "default_median_elapsed = [median(default_times[n]) for n in num_particles_list]\n",
    "\n",
    "custom_kls = [kl_divergence(gold_standard_histogram, custom_histograms[n]) for n in num_particles_list]\n",
    "custom_median_elapsed = [median(custom_times[n]) for n in num_particles_list];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we plot the results. On the left, we plot the error as measured against the gold standard (KL divergence) as a function of the number of particles used in the importance smapling algorithm. On the right we plot the error versus the median time per run of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PyPlot.figure(figsize=(8, 4))\n",
    "\n",
    "PyPlot.subplot(1, 2, 1)\n",
    "PyPlot.plot(num_particles_list, default_kls, label=\"default\")\n",
    "PyPlot.plot(num_particles_list, custom_kls, label=\"custom\")\n",
    "PyPlot.legend()\n",
    "PyPlot.ylabel(\"Error\")\n",
    "PyPlot.xlabel(\"number of particles\")\n",
    "\n",
    "PyPlot.subplot(1, 2, 2)\n",
    "PyPlot.scatter(default_median_elapsed, default_kls, label=\"default\")\n",
    "PyPlot.scatter(custom_median_elapsed, custom_kls, label=\"custom\")\n",
    "PyPlot.legend()\n",
    "PyPlot.ylabel(\"Error\")\n",
    "PyPlot.xlabel(\"Median samples per second\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot on the right, we see that there is a regime where using the custom proposal gives less than half the error over using the default proposal, for the same amount of running time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Learning a custom proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was not too difficult to design a custom proposal for the speed based on a heuristic estimator. However, sometimes it is not straightforward to manually design a custom proposal. In such cases, we can still design a *sketch* for a custom proposal, and *train* the parameters of the proposal automatically, to fill in our missing knowledge, or to generate code that it would be hard to program by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, consider the destination. The default proposal distribution for the destination is the uniform distribution on the scene region. Intuitively, it should be possible to for a short and fast program to narrow down the scene region based on the measurements. However, writing a program that is robust, by hand, is challening. This section shows how to learn a custom proposal for the destination from data simulated from the model. The idea of training proposal distribution on data simulated from a generative model has been called *amortized inference* [3] and *inference compilation* [4], and is also the core of the wake-sleep algorithm [5].\n",
    "\n",
    "\n",
    "- [3] Stuhlmller, Andreas, Jacob Taylor, and Noah Goodman. \"Learning stochastic inverses.\" Advances in neural information processing systems. 2013.\n",
    "\n",
    "- [4] Le, Tuan Anh, Atilim Gunes Baydin, and Frank Wood. \"Inference compilation and universal probabilistic programming.\" arXiv preprint arXiv:1610.09900 (2016).\n",
    "\n",
    "- [5] Hinton, Geoffrey E., et al. \"The\" wake-sleep\" algorithm for unsupervised neural networks.\" Science 268.5214 (1995): 1158-1161."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid(x) = 1 ./ (1 .+ exp.(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function dest_x_neural_net(nn_params, x_first::Real, y_first::Real, x_last::Real, y_last::Real)\n",
    "    (W1, b1, W2, b2, W3, b3) = nn_params\n",
    "    input_layer = [x_first, y_first, x_last, y_last]\n",
    "    hidden_layer_1 = sigmoid(W1 * input_layer .+ b1)\n",
    "    hidden_layer_2 = sigmoid(W2 * hidden_layer_1 .+ b2)\n",
    "    output_layer = exp.(W3 * hidden_layer_2 .+ b3)\n",
    "end\n",
    "\n",
    "function dest_y_neural_net(nn_params, x_first::Real, y_first::Real, x_last::Real, y_last::Real, dest_x::Real)\n",
    "    (W1, b1, W2, b2, W3, b3) = nn_params\n",
    "    input_layer = [x_first, y_first, x_last, y_last, dest_x]\n",
    "    hidden_layer_1 = sigmoid(W1 * input_layer .+ b1)\n",
    "    hidden_layer_2 = sigmoid(W2 * hidden_layer_1 .+ b2)\n",
    "    output_layer = exp.(W3 * hidden_layer_2 .+ b3)\n",
    "end\n",
    "\n",
    "@gen function custom_dest_proposal(measurements::Vector{Point}, scene::Scene)\n",
    "        \n",
    "    @param x_W1::Matrix{Float64}\n",
    "    @param x_b1::Vector{Float64}\n",
    "    @param x_W2::Matrix{Float64}\n",
    "    @param x_b2::Vector{Float64}\n",
    "    @param x_W3::Matrix{Float64}\n",
    "    @param x_b3::Vector{Float64}\n",
    "    \n",
    "    @param y_W1::Matrix{Float64}\n",
    "    @param y_b1::Vector{Float64}\n",
    "    @param y_W2::Matrix{Float64}\n",
    "    @param y_b2::Vector{Float64}\n",
    "    @param y_W3::Matrix{Float64}\n",
    "    @param y_b3::Vector{Float64}\n",
    "    \n",
    "    num_x_bins = length(x_b3)\n",
    "    num_y_bins = length(y_b3)\n",
    "    \n",
    "    x_first = measurements[1].x\n",
    "    x_last = measurements[end].x\n",
    "    y_first = measurements[1].y\n",
    "    y_last = measurements[end].y\n",
    "    \n",
    "    # sample dest_x\n",
    "    x_bounds = collect(range(scene.xmin, stop=scene.xmax, length=num_x_bins+1))\n",
    "    x_probs = dest_x_neural_net((x_W1, x_b1, x_W2, x_b2, x_W3, x_b3), x_first, y_first, x_last, y_last)\n",
    "    dest_x = @addr(Gen.piecewise_uniform(x_bounds, x_probs / sum(x_probs)), :dest_x)\n",
    "    \n",
    "    # sample dest_y\n",
    "    y_bounds = collect(range(scene.xmin, stop=scene.xmax, length=num_y_bins+1))\n",
    "    y_probs = dest_y_neural_net((y_W1, y_b1, y_W2, y_b2, y_W3, y_b3), x_first, y_first, x_last, y_last, dest_x)\n",
    "    @addr(Gen.piecewise_uniform(y_bounds, y_probs / sum(y_probs)), :dest_y)\n",
    "    \n",
    "    nothing\n",
    "end\n",
    "\n",
    "num_x_bins = 5\n",
    "num_y_bins = 5\n",
    "\n",
    "# architecture of the neural network\n",
    "num_hidden_1 = 50\n",
    "num_hidden_2 = 50\n",
    "\n",
    "import Random\n",
    "Random.seed!(1)\n",
    "\n",
    "# set parameters for dest_x_neural_net predictor network\n",
    "init_param!(custom_dest_proposal, :x_W1, 0.001 * rand(num_hidden_1, 4))\n",
    "init_param!(custom_dest_proposal, :x_b1, 0.001 * rand(num_hidden_1))\n",
    "init_param!(custom_dest_proposal, :x_W2, 0.001 * rand(num_hidden_2, num_hidden_1))\n",
    "init_param!(custom_dest_proposal, :x_b2, 0.001 * rand(num_hidden_2))\n",
    "init_param!(custom_dest_proposal, :x_W3, 0.001 * rand(num_x_bins, num_hidden_2))\n",
    "init_param!(custom_dest_proposal, :x_b3, 0.001 * rand(num_x_bins))\n",
    "\n",
    "# set parameters for dest_y_neural_net predictor network\n",
    "init_param!(custom_dest_proposal, :y_W1, 0.001 * rand(num_hidden_1, 5))\n",
    "init_param!(custom_dest_proposal, :y_b1, 0.001 * rand(num_hidden_1))\n",
    "init_param!(custom_dest_proposal, :y_W2, 0.001 * rand(num_hidden_2, num_hidden_1))\n",
    "init_param!(custom_dest_proposal, :y_b2, 0.001 * rand(num_hidden_2))\n",
    "init_param!(custom_dest_proposal, :y_W3, 0.001 * rand(num_y_bins, num_hidden_2))\n",
    "init_param!(custom_dest_proposal, :y_b3, 0.001 * rand(num_y_bins));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we visualize the proposal density for a given data set. The cell below computes the proposal density at a grid of points in the scene, and returns a list of `tiles` that can be rendered on top of the scene by the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_proposal_tiles(measurements::Vector{Point}, scene::Scene, num_x_bins::Int, num_y_bins::Int)\n",
    "    dest_proposal_tiles = []\n",
    "    xspan = scene.xmax - scene.xmin\n",
    "    yspan = scene.ymax - scene.ymin\n",
    "    w = xspan / num_x_bins\n",
    "    h = yspan / num_y_bins\n",
    "    for col=1:num_x_bins\n",
    "        for row=1:num_y_bins\n",
    "            x = scene.xmin + (col - 1) * w\n",
    "            y = scene.ymin + (row - 1) * h\n",
    "            assmt = DynamicAssignment()\n",
    "            assmt[:dest_x] = x + (w/2)\n",
    "            assmt[:dest_y] = y + (h/2)\n",
    "            (weight, _) = assess(custom_dest_proposal, (measurements, scene), assmt)\n",
    "            tile = Dict(\"x\" => x, \"y\" => y, \"w\" => w, \"h\" => h, \"density\" => exp(weight))\n",
    "            push!(dest_proposal_tiles, tile)\n",
    "        end\n",
    "    end\n",
    "    max_density = maximum([tile[\"density\"] for tile in dest_proposal_tiles])\n",
    "    for tile in dest_proposal_tiles\n",
    "        tile[\"density\"] /= max_density\n",
    "    end\n",
    "    dest_proposal_tiles\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we show the proposal distribution prior to training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = make_proposal_tiles(measurements, scene, 5, 5)\n",
    "info = Dict(\"measurements\" => measurements, \"scene\" => scene, \"start\" => start, \"tiles\" => tiles)\n",
    "viz = Viz(server, joinpath(@__DIR__, \"overlay-viz/dist\"), info)\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the entire scene is colored the same color. The untrained proposal is approximately uniform on the entire scene, just like the default proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Next, we train the network using stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGDOptimizer(Set(get_param_names(custom_dest_proposal)), 10, 10000, 100, 100;\n",
    "    step_size_init=0.1, step_size_beta=1000)\n",
    "\n",
    "function data_generator()\n",
    "    \n",
    "    local assmt\n",
    "    \n",
    "    # obtain a trace of the model where planning succeeded\n",
    "    done = false\n",
    "    while !done\n",
    "        (assmt, _, retval) = propose(model, (scene, dt, num_ticks))\n",
    "        (start, dest, speed, noise, maybe_path) = retval\n",
    "        done = (maybe_path != nothing)\n",
    "    end\n",
    "\n",
    "    measurements = [Point(assmt[:meas => i => :x], assmt[:meas => i => :y]) for i=1:num_ticks]\n",
    "    inputs = (measurements, scene)\n",
    "    \n",
    "    constraints = DynamicAssignment()\n",
    "    constraints[:dest_x] = assmt[:dest_x]\n",
    "    constraints[:dest_y] = assmt[:dest_y]\n",
    "    \n",
    "    (inputs, constraints)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train!(optimizer, custom_dest_proposal, data_generator, verbose=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now visualize the trained proposal distribution for the given data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = make_proposal_tiles(measurements, scene, 5, 5)\n",
    "info = Dict(\"measurements\" => measurements, \"scene\" => scene, \"start\" => start, \"tiles\" => tiles)\n",
    "viz = Viz(server, joinpath(@__DIR__, \"overlay-viz/dist\"), info)\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this data set, the proposal distribution seems to make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can combine the custom proposal for the destination with the custom proposal for the speed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function custom_proposal(measurements::Vector{Point}, scene::Scene, guess, num_used)\n",
    "    @splice(custom_dest_proposal(measurements, scene))\n",
    "    @splice(propose_speed(guess, num_used))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We write a new inference algorithm that uses importance sampling based on this new trained proposal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function do_inference_trained(scene::Scene, dt::Float64, num_ticks::Int,\n",
    "                              start::Point, measurements::Vector{Point},\n",
    "                              num_particles::Int)\n",
    "    (guess, num_used) = guess_speed(measurements, dt)\n",
    "    \n",
    "    observations = DynamicAssignment()\n",
    "    observations[:start_x] = start.x\n",
    "    observations[:start_y] = start.y\n",
    "    for (i, m) in enumerate(measurements)\n",
    "        observations[:meas => i => :x] = m.x\n",
    "        observations[:meas => i => :y] = m.y\n",
    "    end\n",
    "    \n",
    "    # use importance sampling with resampling to obtain an inferred trace\n",
    "    (trace, _) = importance_resampling(model, (scene, dt, num_ticks), observations, \n",
    "        custom_proposal, (measurements, scene, guess, num_used), num_particles)\n",
    "    \n",
    "    trace\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we show some samples from this new algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = Dict(\"measurements\" => measurements, \"scene\" => scene, \"start\" => start)\n",
    "viz = Viz(server, joinpath(@__DIR__, \"overlay-viz/dist\"), info)\n",
    "openInNotebook(viz)\n",
    "sleep(5)\n",
    "for i=1:1000\n",
    "    trace = do_inference_trained(scene, dt, num_ticks, start, measurements, 50)\n",
    "    putTrace!(viz, i, trace_to_dict(trace))\n",
    "end\n",
    "displayInNotebook(viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now generate histograms for the destination distributions for the new algorithm, for various numbers of particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_histograms = Dict{Int,Vector{Float64}}()\n",
    "trained_times = Dict{Int,Vector{Float64}}()\n",
    "num_particles_list = [1, 3, 10, 30, 100]\n",
    "\n",
    "nruns = 1000\n",
    "for n in num_particles_list\n",
    "    \n",
    "    println(\"evaluating algorithms with num_particles=$n\")\n",
    "    \n",
    "    # run importance sampling with default proposal\n",
    "    traces = Vector{Any}(undef, nruns)\n",
    "    times = Vector{Float64}(undef, nruns)\n",
    "    for i=1:nruns\n",
    "        start_time = time_ns()\n",
    "        traces[i] = do_inference_trained(scene, dt, num_ticks, start, measurements, n)\n",
    "        times[i] = (time_ns() - start_time)/1e9\n",
    "    end\n",
    "    trained_histograms[n] = make_location_histogram(traces, nrows, ncols, scene)\n",
    "    trained_times[n] = times\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute KL divergences between the gold standard distribution and these histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trained_kls = [kl_divergence(gold_standard_histogram, trained_histograms[n]) for n in num_particles_list]\n",
    "trained_median_elapsed = [median(trained_times[n]) for n in num_particles_list];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we plot the results and compare the three importance sampling algorithms developed in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PyPlot.figure(figsize=(8, 4))\n",
    "\n",
    "PyPlot.subplot(1, 2, 1)\n",
    "PyPlot.plot(num_particles_list, default_kls, label=\"default\")\n",
    "PyPlot.plot(num_particles_list, custom_kls, label=\"custom\")\n",
    "PyPlot.plot(num_particles_list, trained_kls, label=\"trained\")\n",
    "PyPlot.legend()\n",
    "PyPlot.ylabel(\"Error\")\n",
    "PyPlot.xlabel(\"number of particles\")\n",
    "\n",
    "PyPlot.subplot(1, 2, 2)\n",
    "PyPlot.scatter(default_median_elapsed, default_kls, label=\"default\")\n",
    "PyPlot.scatter(custom_median_elapsed, custom_kls, label=\"custom\")\n",
    "PyPlot.scatter(custom_median_elapsed, trained_kls, label=\"trained\")\n",
    "PyPlot.legend()\n",
    "PyPlot.ylabel(\"Error\")\n",
    "PyPlot.xlabel(\"Median samples per second\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.2",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
